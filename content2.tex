
\chapter{Metodologia badań}
Niniejszy rozdział będzie opisywał przeprowadzone etapy badań. 

W pierwszej kolejności wymienione zostaną narzędzia. Następnie przedstawione będą elementy procesu eksploracji danych niedotyczące pracy z algorytmami uczenia maszynowego, takie jak: wyszukiwanie, zbieranie, ekstrakcja cech, czyszczenie i normalizacja danych. Nawiązując do ankiety przeprowadzonej przez CrowdFlower \cite{ds_report}: podczas badań związanych z {\em Big Data}, znacząca większość czasu pochłaniana jest przez zbieranie i przygotowanie danych. Zasada ta miała swoje odzwierciedlenie również w tej pracy, szczególnie, że przedmiotem badań było wideo, które wymaga wykorzystania dużych zasobów podczas tych procesów (w odróżnieniu od na przykład danych tekstowych). 

Na końcu opisany zostanie proces trenowania, wyniki predykcji z modeli powstałych w oparciu o algorytmy wymienione z poprzedniej sekcji.
%https://visit.figure-eight.com/rs/416-ZBE-142/images/CrowdFlower_DataScienceReport.pdf -> slajd 5
\label{cha:pierwszyDokument}

\section{Narzędzia}
Specyfika badań wymagała narzędzi będących w stanie sprawnie przetwarzać duże ilości informacji oraz zautomatyzować procesy związane z pobieraniem i przygotowaniem danych. Do tych zadań, jako optymalne rozwiązanie, został wybrany język Python. Według badań \cite{python} jest to jeden z najpopularniejszych języków programowania w {\em Data science}. Python pozwala użytkownikowi na korzystanie z zalet programowania strukturalnego, w przypadku prostych skryptów wykonujących krótkie zadania (przykładowo: automatyczne kopiowanie i zmienianie nazw w paczkach plików), jak i obiektowego, gdzie konieczne jest ustalenie i ustrukturyzowanie pewnych zależności pomiędzy danymi. Dodatkową jego zaletą jest szereg bibliotek stworzonych z myślą o eksploracji danych. Do badań zostały wykorzystane następujące pakiety: sklearn, pandas, selenium (framework), numpy, matplotlib.\par\par
Poniżej zostały wymienione narzędzia, które posłużyły do ekstrakcji danych z plików wideo:
\begin{itemize}[label=$\bullet$]
\item FFmpeg -- jest aplikacją na licencji {\em opensource}. Dzięki niej otrzymane zostały informacje takie jak: rozdzielczość, dane o próbkowaniu chrominancji, liczba klatek na sekundę. Dodatkowo dzięki FFmpeg skompresowane pliki wideo rozstały rozłożone na pojedyncze ramki.
\item {\em AGH Video Quality Indicators} -- jest ogólnodostępnym oprogramowaniem rozwijanym przez Katedrę Telekomunikacji AGH, przy jego użyciu otrzymane zostały dane o metrykach typu {\em no-reference} \cite{agh_vqm}.
\item VMAF Development Kit (VDK) -- podobnie jak powyższe, VDK jest ogólnodostępnym oprogramowaniem rozwijanym przez Netflix. Zaimplementowane tu zostały algorytmy liczące metryki {\em full-reference} \cite{vdk}.
\end{itemize}
Zbieranie danych i wydobywanie cech wideo odbywało się w dwóch środowiskach: na lokalnie działającej maszynie wirtualnej z systemem operacyjnym Xubuntu oraz na super komputerze Prometeusz z systemem Centos. 

\label{cha:drugiDokument}



\section{Dane}
\label{cha:drugiDokument}

Na rysunku \ref{fig:data_preparation_work_flow} został przedstawiony schemat etapów przygotowywania danych. W celu dokonania obliczeń na dużych danych praktycznie każda z czynności dotycząca przetwarzania ich została zautomatyzowana. Kolejne akapity stanowią opis elementów schematu \ref{fig:data_preparation_work_flow}.



\begin{center}
\includegraphics[ height=11cm, width=15cm]{data_preparation_work_flow}
\captionof{figure}{Schemat kroków wykonanych podczas przygotowywania danych.}
\label{fig:data_preparation_work_flow}
\label{fig:xccs}
\end{center}

\subsection{Zbieranie danych}
Rozpoczęcie przetwarzania danych wymaga w pierwszej kolejności ich zebrania. Dla stworzenia algorytmu oceny jakości, podczas wyszukiwania danych, głównym kryterium było odnalezienie takich baz, gdzie oprócz plików wideo (SRC + PVS) istniała również ich subiektywna ocena (SVQ). Ocena ludzka była konieczna, ponieważ to ona stanowiła dane nadzorcze podczas trenowania modeli. W pracy tej użyto następujące źródła danych:
\begin{itemize}
\item Subjective quality of H.264/SVC videos using ACR-HR method in VGA -- baza danych udostępniona dzięki The Institut de Recherche en Communications et Cybernétique de Nantes. W jej skład wchodzi około 300 plików wideo, ich czas trwania to: 10-12s, a rozdzielczość wszystkich wynosi: 640x480 \cite{pitrey:hal-00608310}.
\item Lab for Video and Image Analysis – LFOVIA -- jest grupą badaczy z Indian Institute of Technology Hyderabad zajmujących się tematyką jakości wideo. Dzięki udostępnionym przez nich plikom,  baza danych wejściowych w niniejszej pracy powiększyła się o 40 nowych obrazów w wysokich rozdzielczościach: FHD (1920x1080), UHD (3840x2160) i czasie trwania po 120 sekund każdy \cite{india}.
\item LIVE Netflix Video Quality of Experience Database -- baza danych stworzona przez naukowców z The University of Texas at Austin. W jej skład wchodzi 26 wideo o rozdzielczości 1920x1080, o długości 120 sekund każdy \cite{netflix_1}\cite{netflix_11}.
\item LIVE-NFLX-II Subjective Video QoE Database -- również stworzona przez The University of Texas at Austin w celu badań nad optymalnym przesyłem wideo w sieci. W bazie danych znajduje się 420 plików wideo o rozdzielczości FHD i czasie trwania około 40 sekund.
\item EPFL-PoliMI video quality assessment database -- Baza plików wideo utworzona przez dwie współpracujące uczelnie: Politecnico di Milano - Włochy i Ecole Polytechnique Fédérale de Lausanne - Szwajcaria. Dane składają się z 12 obrazów referencyjnych (SRC) oraz z aplikacji pozwalającej wygenerować dla nich PVSs. W ten sposób zostały uzyskane około 150 nowych filmów do badań w dwóch rozdzielczościach: 704x576, 352x288 i o czasie trwania około 10s \cite{italy}\cite{italy_2}\cite{italy_3}.
\end{itemize}
Początkowo w badaniach brała udział jeszcze jedna baza wideo z 220-oma plikami. Niestety, jak się okazało plik referencyjny oraz jego zniekształcone wersje posiadały różne wartości fps, przez co metryki typu VMAF nie były w stanie podać miarodajnych wyników. Cała więc baza musiała zostać pominięta.\par

\subsection{Ekstrakcja cech}
Kolejnym krokiem po zebraniu danych była ekstrakcja cech wideo, które później miały być użyte podczas przygotowywania modeli. W celu otrzymania cech należało każde wideo przekształcić do serii pojedynczych ramek w formacie YUV. 

Dalszy proces ekstrakcji był o tyle problematyczny, że różne, do tego wykorzystywane narzędzia, wymagały w różny sposób dostosowanych danych. Co więcej, nieskompresowane wideo zajmuje bardzo dużo przestrzeni dyskowej, a sam proces przetwarzania wideo wymaga również znacznego nakładu pracy dla procesora. Cechy biorące udział w badaniach to: blokowość, aktywność przestrzenna, aktywność czasowa, letterbox, pillarbox, straty bloków, rozmycie, wyciemnienie, zamrożenie, ekspozycja, kontrast, jasność, szum, PSNR, SSIM, MS-SSIM, VMAF, czas trwania, próbkowanie chrominancji, liczba klatek na sekundę.\par

Dane dotyczące metryk $full$-$renerence$ oraz $no$-$reference$ zostały uzyskane na każdą z ramek. W następnym kroku wartości te zostały uśrednione na całe wideo. Wyjątkiem były SSIM i MS\--SSIM tu informacje zostały uzyskane na całe wideo. Cechy pochodzące z obu źródeł: VDK i AGH Video Quality Indicators zostały ujednolicone i zapisane wspólnie w postaci pliku CSV.\par

Dodatkowo w badaniu postanowiono dodać jeszcze jedną cechę, która mogła by mieć wpływ na wynik subiektywny, to znaczy ilość różnych rozdzielczości w bazie. Przykładowo w zestawieniu, w którym pliki posiadają różne rozdzielczości, te z ich wyższą wartością (np. FHD) mogą mocniej kontrastować z tymi o niższej, przez to ocena subiektywna może okazać wyższa. W pracy tej rozpoznano dwa przypadki, kiedy baza danych zawiera pliki o jednej rozdzielczości i baza danych zawiera pliki o dwóch rozdzielczościach. Cecha ta została wprowadzona jako binarna cecha nominalna dla każdego z wideo i odpowiada na pytanie czy plik pochodzi z bazy o jednej rozdzielczości. Jeżeli tak to wartość jej przyjmuje 1, w innym wypadku 0.  \par

Powyższy czynnik jest sztucznie stworzoną cechą, w komercyjnym wykorzystaniu trudną do otrzymania, ponieważ wymagało by to dostępu do obrazów obejrzanych przez widza bezpośrednio wcześniej. Cechę tę można również rozwinąć o inne atrybuty wideo, tak aby móc w lepszy sposób przedstawić różnice pomiędzy ocenianym plikiem, a pozostałą resztą, co leży poza zakresem tego opracowania.\par

Jako dane nadzorujące użyto subiektywną ocenę ludzką.\par

\subsection{Normalizacja i czyszczenie danych}
W zbiorze plików pochodzących od badaczy z Uniwersytetu w Texasie ocena subiektywna została przekazana po znormalizowaniu $z$-$score$, gdzie zakres wartości zawiera się pomiędzy -3 a 3. W celu otrzymania miarodajnych wyników dane z pozostałych baz również zostały w ten sam sposób znormalizowane.\par
Podczas procesu przygotowywania danych jak i późniejszej ekstrakcji cech mogły nastąpić pewne wyjątki, które uniemożliwiły otrzymanie poprawnego wyniku. W takim przypadku cały wiersz dotyczący danego wideo był pomijany podczas tworzenia modeli.

\subsection{Podział danych}

Przy tworzeniu modeli została wykorzystana implementacja algorytmów zawarta w module języka Python -- sklearn. Instancje klas, przedstawiające modele, przyjmują jako dane wejściowe dane w formacie macierzy. Dlatego pliki CSV zostały, podczas działania skryptu, przekształcone do typu DataFarme. Wspierany jest on przez moduł, ułatwiający prace z dużymi danymi -- pandas.\par

Przy eksploatowaniu danych często stosowaną techniką jest $cross$ $validation$. Polega ona na podziale dostępnych danych na dane treningowe i testowe. Można tu wykorzystać zasadę podziału 80:20, co oznacza ze 80 części danych jest przeznaczonych na dane treningowe, a 20 na dane testujące. Dobrą praktyką jest, aby w obu z tych grup znalazły się dane z całego przekroju bazy danych. Zabieg ten ma na celu pozwolenie na identyfikacje  problemu generalizacji czy nad dopasowania. 

W przedstawionej pracy proces podziału danych należało przeprowadzić, tak aby uwzględnić  całe grupy --  SRC i jego PSV. Dane z jednej takiej grupy powinny w całości znaleźć się w podzbiorze danych testowych bądź treningowych. Nie zastosowanie tego zabiegu mogło by poskutkować niemiarodajnym wysokim wynikiem R-kwadrat. Wysoki R-kwadrat powinien wskazywać na dużą trafność modelu. Jednak w tym przypadku oznaczało by to, że odnajduje on zależności związane z grupami wideo, które wzięły udział w tym badaniu. Zaproponowany tu podział pozwala na uniknięcie tego niepożądanego efektu. Schemat podziału jest przedstawiony na rysunku \ref{fig:podzial_danych}.

\begin{center}
\includegraphics[ height=5cm, width=10cm]{podzial_danych}
\captionof{figure}{Przykładowy podział danych na dane testowe i treningowe (80:20). Niebieskie prostokąty odnoszą się do danych treningowych, a zielone do danych testowych.}
\label{fig:podzial_danych}
\label{fig:xccs}
\end{center}
Ostatnim etapem podczas przygotowywania danych było połączanie elementów z każdej z grup. Od tego momentu wektor danych wejściowych podczas przygotowywania modelu odnosi się do pojedynczego pliku wideo.


\clearpage

\subsection{Podsumowanie danych}
Poniższa tabela \ref{tab:tabela} przedstawia uzyskane dane 


\begin{table}[!hbp]
\centering
\begin{tabular}{|c|l|l|l|l|}
\hline
\multicolumn{5}{|c|}{5 baz danych, ponad 800 wektorów danych, ponad 100 paczek plików wideo} \\ \hline
\multicolumn{5}{|c|}{21 cech statystycznych} \\ \hline
\multicolumn{2}{|c|}{ilościowe} & \multicolumn{3}{c|}{jakościowe} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{@{}l@{}}blokowość, aktywność przestrzenna, aktywność czasowa,\\ letterbox, pillarbox, straty bloków, rozmycie, wyciemnienie, \\ zamrożenie, ekspozycja, kontrast, jasność, szum, \\ PSNR, SSIM, MS-SSIM, VMAF, czas trwania,\end{tabular}} & \multicolumn{3}{l|}{\begin{tabular}[c]{@{}l@{}}próbkowanie chrominancji,\\ rozdzielczość, \\ liczba dostępnych rozdzielczości\end{tabular}} \\ \hline
\end{tabular}
\caption{Podsumowanie przygotowania danych}
\label{tab:tabela}
\end{table}





\section{Proces budowania i testowania modeli}
\label{cha:drugiDokument}


Z uwagi na specyfikę przygotowania danych treningowych i testowych przygotowano wiele modeli. Każdorazowe wykonanie programu przygotowania modeli generuje ich zbiór, po jednym modelu dla każdego sprawdzanego algorytmu na każdy testowany zestaw danych. Wykonania dla tego skryptu zostały powtórzone wiele razy. Poniższy akapit wyjaśnia potrzebę tego zabiegu.

Podział danych 80:20 dotyczy paczek SRC + PSV, natomiast budowa modeli odbywa się już na podstawie danych z pojedynczych plików wideo. Dlatego może zaistnieć sytuacja kiedy większość małych paczek (na przykład po tylko 3 pliki wideo) znajdą się w danych treningowych, a większość dużych (na przykład po 15 wideo) w danych testujących. Tym samym faktyczny podział może wynosić w skrajnym przypadku 50:50, zamiast 80:20 (taki sam odstęp może wystąpić w drugą stronę). Dlatego  przy  każdym uruchomieniu aplikacji, podział zgromadzonych danych dobywał się na zasadzie losowo wybranych paczek do każdej grup -- danych trenujących i testujących, przy zachowaniu podziału 80:20.\par

Wykres \ref{fig:execution} odnosi się do przeprowadzonego eksperymentu, który pomógł wybrać optymalną liczbę iteracji dla wyżej omówionej techniki. Linie przedstawiają uśrednioną wartość R-kwadrat na liczbę modeli(w tym przypadku powstałych na bazie zestawów danych wejściowych numer: 18, 7, 25 -- tabela 3.2) biorących udział podczas jej obliczania. Czytając ten wykres można stwierdzić, że dla każdego z algorytmów wyniki stabilizują się satysfakcjonującym poziomie przy około 60 modelach. W celu uniknięcia niemiarodajnych wyników w dalszych badaniach  wybrano liczbę (z pewnym zapasem) 70 modeli na podstawie których  obliczany był uśredniony R-kwadrat.

\begin{center}
	\includegraphics[ height=8cm, width=12cm]{execution}
	\captionof{figure}{Uśredniony R-kwadrat na liczbę modeli biorących udział w jego liczeniu. Badanie dla zestawu 18 z tabeli 3.2.}
	\label{fig:execution}
	\label{fig:xccs}
\end{center}

W badaniach postanowiono sprawdzić  modele trenowane w oparciu o: każdą z osobna metrykę FR, wybrane metryki NR i ich niektóre kombinacje. Uruchomienia sekwencji budowania i testowania odbywały się na zestawach cech prezentowanych w tabeli 3.2. Dalsze rozdziały będą odnosić się do poniższej numeracji w kontekście zestawów cech.

\newgeometry{top=3mm, bottom=20mm, right=9mm} 
\begin{table}[]
	\raggedright
	\begin{tabular}{|l|l|}
		\hline
		\textbf{\begin{tabular}[c]{@{}l@{}}Numer \\ zestawu\end{tabular}} & \textbf{Cechy}                                                                                                                                                                                                                                                                 \\ \hline
		1                                                                 & VMAF                                                                                                                                                                                                                                                                           \\ \hline
		2                                                                 & VMAF, SSIM                                                                                                                                                                                                                                                                     \\ \hline
		3                                                                 & MS-SSIM                                                                                                                                                                                                                                                                        \\ \hline
		4                                                                 & PSNR                                                                                                                                                                                                                                                                           \\ \hline
		5                                                                 & PSNR, VMAF                                                                                                                                                                                                                                                                     \\ \hline
		6                                                                 & PSNR, VMAF, SSIM, MS-SSIM                                                                                                                                                                                                                                                      \\ \hline
		7                                                                 & \begin{tabular}[c]{@{}l@{}}PSNR, VMAF, SSIM, MS-SSIM, blokowość, aktywność przestrzenna, pillarbox, \\ straty bloków, rozmycie, aktywność czasowa, wyciemnienie, ekspozycja, kontrast, \\ jasność, czas trwania, rozdzielczości\end{tabular}                                   \\ \hline
		8                                                                 & \begin{tabular}[c]{@{}l@{}}PSNR, VMAF, SSIM, MS-SSIM, blokowość, aktywność przestrzenna, pillarbox, straty bloków, \\ rozmycie, aktywność czasowa, wyciemnienie, ekspozycja, kontrast, jasność, czas trwania, rozdzielczości, \\ liczba dostępnych rozdzielczości\end{tabular} \\ \hline
		9                                                                 & PSNR, VMAF, SSIM, MS-SSIM, rozmycie, straty bloków                                                                                                                                                                                                                             \\ \hline
		10                                                                & PSNR, VMAF, SSIM, MS-SSIM, rozmycie, straty bloków, liczba dostępnych rozdzielczości                                                                                                                                                                                           \\ \hline
		11                                                                & PSNR, VMAF, SSIM, MS-SSIM, jasność                                                                                                                                                                                                                                             \\ \hline
		12                                                                & PSNR, VMAF, SSIM, MS-SSIM, jasność, blokowość, straty bloków, rozmycie                                                                                                                                                                                                         \\ \hline
		13                                                                & \begin{tabular}[c]{@{}l@{}}PSNR, VMAF, SSIM, MS-SSIM, jasność, blokowość, straty bloków, rozmycie, \\ liczba dostępnych rozdzielczości\end{tabular}                                                                                                                            \\ \hline
		14                                                                & PSNR, VMAF, SSIM, MS-SSIM, jasność, ekspozycja                                                                                                                                                                                                                                 \\ \hline
		15                                                                & PSNR, VMAF, SSIM, MS-SSIM, jasność, ekspozycja, liczba dostępnych rozdzielczości                                                                                                                                                                                               \\ \hline
		16                                                                & PSNR, VMAF, SSIM, MS-SSIM, jasność, liczba dostępnych rozdzielczości                                                                                                                                                                                                           \\ \hline
		17                                                                & PSNR, VMAF, SSIM, MS-SSIM, czas trwania                                                                                                                                                                                                                                        \\ \hline
		18                                                                & PSNR, VMAF, SSIM, MS-SSIM, czas trwania, liczba dostępnych rozdzielczości                                                                                                                                                                                                      \\ \hline
		19                                                                & \begin{tabular}[c]{@{}l@{}}PSNR, VMAF, SSIM, MS-SSIM, czas trwania, liczba dostępnych rozdzielczości,\\  rozdzielczości\end{tabular}                                                                                                                                           \\ \hline
		20                                                                & PSNR, SSIM                                                                                                                                                                                                                                                                     \\ \hline
		21                                                                & SSIM                                                                                                                                                                                                                                                                           \\ \hline
		22                                                                & blokowość                                                                                                                                                                                                                                                                      \\ \hline
		23                                                                & \begin{tabular}[c]{@{}l@{}}blokowość, aktywność przestrzenna, pillarbox, straty bloków, rozmycie, aktywność czasowa,\\  wyciemnienie, ekspozycja, kontrast, jasność, rozdzielczości, liczba dostępnych rozdzielczości\end{tabular}                                             \\ \hline
		24                                                                & \begin{tabular}[c]{@{}l@{}}blokowość, aktywność przestrzenna, pillarbox, straty bloków, rozmycie, aktywność czasowa, \\ wyciemnienie, ekspozycja, kontrast, jasność, czas trwania, rozdzielczości\end{tabular}                                                                 \\ \hline
		25                                                                & \begin{tabular}[c]{@{}l@{}}blokowość, aktywność przestrzenna, pillarbox, straty bloków, rozmycie, aktywność czasowa,\\ wyciemnienie, ekspozycja,  kontrast, jasność, czas trwania, rozdzielczości, liczba dostępnych rozdzielczości\end{tabular}                               \\ \hline
		26                                                                & straty bloków                                                                                                                                                                                                                                                                  \\ \hline
		27                                                                & rozmycie                                                                                                                                                                                                                                                                       \\ \hline
		28                                                                & jasność                                                                                                                                                                                                                                                                        \\ \hline
		29                                                                & kontrast                                                                                                                                                                                                                                                                       \\ \hline
		30                                                                & ekspozycja                                                                                                                                                                                                                                                                     \\ \hline
	\end{tabular}
	\caption{Numeracja zestawów danych biorących udział w badaniu.}
	\label{tab:tabela2}
\end{table}
\AddThispageHook{\thispagestyle{empty}}%
\restoregeometry

\clearpage
\section{Parametry modeli}
\label{cha:drugiDokument}
W niniejszej pracy zostały przetestowane cztery algorytmy uczenia maszynowego przedstawione w części teoretycznej. Parametry definiujące ich działanie zostały dobrane na zasadzie obserwacji kolejnych prób i wiedzy na temat ich działania. Proces ten został opisany w podrozdziale 3.4.1. Następnie wyselekcjonowane parametry zostały przedstawione w podrozdziale 3.4.2. Dla modeli zbudowanych z ich udziałem osiągnięto najwyższy wskaźnika R-kwadrat dla tu przeprowadzonych badań.

\subsection{Testy parametrów}
\todo{podobnie to techniki Hyperparameter optimization}
W pracy tej skupiono się na wybranych parametrach podawanych  przez badacza w czasie definiowania modelu. W celu otrzymania odpowiednio dopasowanych parametrów została przeprowadzona seria testów. W każdym z nich badano wpływ zadanego zakresu wartości dla wybranych parametrów na wyniki modeli. Procedura ta została wykonana dla trzech wybranych zestawów  po jednym zestawie z trzech typów dostępnych w puli. Zestaw 24 jako cechy wyłącznie NR, zestaw 6 jako cechy wyłącznie FR, Zestaw 7 jako kombinacja cech NR i FR. 

\vspace{5mm}

Poniżej znajdują się poglądowo przedstawione badane parametry: 
\begin{itemize}[label=$\bullet$]
	\item SVR 
		\begin{itemize}[noitemsep,nolistsep]
			\item \textbf{parametr $C$} -- odnosi się do oceny straty związanej z próbkami danych poza marginesem podczas procesu trenowania.	\todo{zmienic opis, do podobnego jak w czesci teoretycznej- zmienic pojecia deneralizacji i biasu} Zbyt duża jego wartość może sprawić, że model stanie się bardziej wrażliwy zanieczyszczone dane. Mała wartość może skutkować generalizacją. Sprawdzany zakres: 0.7, 10, 20, 30, 40.
			\item \textbf{parametr $\epsilon$} -- określa rozmiar akceptowalnego błędu podczas trenowania modelu. Sprawdzany zakres: 0.1, 0.3, 0.4, 0.5.
		\end{itemize}  
	
	\item Las losowy
	\begin{itemize}[noitemsep,nolistsep]
		\item \textbf{liczba drzew} -- czyli liczba drzew biorących udział w "głosowaniu". Generalnie większa ich liczba powinna  zwiększyć dopasowanie modelu, jednak przy ich pewnej liczbie dokładność już nie rośnie, natomiast zwiększają się cały czas koszty obliczeniowe modelu. Sprawdzany zakres: 10, 20, 40, 60, 70, 100.
		\item \textbf{głębokość drzew} -- odnosi się do liczby podziałów dokonywanych w obrębie drzewa. Głębsze drzewa są w stanie uzyskać z danych więcej informacji. Negatywnym zjawiskiem jest natomiast zbyt duża jego wartość, prowadzi to do nad dopasowania. Sprawdzany zakres: 2, 6, 8, 10.
	\end{itemize}  
	
	\item Sieć neuronowa
	\begin{itemize}[noitemsep,nolistsep]
		\item \textbf{liczba ukrytych warstw} oraz \textbf{liczna neuronów w pojedynczej warstwie} -- w ogólności im ich liczba jest większa tym model powinien być w stanie rozpoznać bardziej zaawansowane zależności w danych. Jednak zbyt duże wartości dla tego parametru mogą doprowadzić do nad dopasowania oraz  wydłużonego czasu trenowania. Sprawdzany zakres dla liczby warstw: 1, 2, 3, 4 oraz dla liczby neuronów: 2, 3, 5, 9, 13, 15.
	\end{itemize}   
\end{itemize}

Wyniki eksperymentu sa zwizualizowane na poniższych wykresach:

\begin{figure}[H]
	\includegraphics[ height=10cm, width=16cm]{params_svr}
	\captionof{figure}{Wpływ parametrów: C oraz $\epsilon$ na wyniki R-kwadrat dla modeli na bazie algorytmu SVR.}
	\label{fig:params_svr}
	\label{fig:xccs}
\end{figure}



\begin{center}
	\includegraphics[ height=10cm, width=18cm]{params_rf}
	\captionof{figure}{Wpływ parametrów: liczba drzew oraz głębokość drezw na wyniki R-kwadrat dla modeli na bazie algorytmu lasu losowego.}
	\label{fig:params_rf}
	\label{fig:xccs}
\end{center}

\begin{center}
	\includegraphics[ height=10cm, width=18cm]{params_nn}
	\captionof{figure}{Wpływ parametrów: liczna neuronów w pojedynczej warstwie ukrytej oraz liczba warst ukrytych na wyniki R-kwadrat dla modeli na bazie algorytmu sieci neuronowej.}
	\label{fig:params_nn}
	\label{fig:xccs}
\end{center}
 

%Skupiono się na kilku parametrach reszta jako const.
%dla metryk z typu FR- postanowiono przetestowac konfiguracje xxx
%itp.
%NR - różne wystepnowanie, nierownomierny rozklad, tylko kilka wydaje sie byc zwiazane z jakoscia. uwzglenic mozliwe typy zaleznosci.
%FR - rownomierny rozklad, bardziej rzetelne, czesciej uwazane za trafne. uwzglednic mozliwe typy zaleznosci


Dla pozostałych parametrów zostały przypisane wartości polecane w artykułach dotyczących tematyki uczenia maszynowego oraz w dokumentacji pakietu sklearn. 

Dla SVR użyta funkcja kernela do wyznaczenia hiperpłaszczyzny to $Radial$ $Basis$ $Function$ (RBF). Przy współczynniku $\gamma$, który mówi jak odległe punkty będą miały wpływ na budowaną hiperpłaszczyznę, skorzystano z metody już zaimplementowanej w pakiecie sklearn, pozwalającej na wyznaczenie bardziej dopasowanej wartości, bazując na dostępnym zbiorze danych. \par


Dla sieci neuronowych ustawiono maksymalną liczbę iteracji algorytmu $Backward$ $Propagation$, po której model będzie gotowy na 1000. Parametr $learning$ $rate$, określający szybkość uczenia, został ustawiony na wartość 0,001. Natomiast funkcję aktywacji stanowiła funkcja ReLU.\par

\vspace{5mm}

Podczas przedstawionego tu eksperymentu zostało stworzonych 20 160 modeli. Na tą liczbę składa się: 24 (20-dla SVR) -- kombinacje parametrów na jeden algorytm, 4 -- algorytmy uczenia maszynowego, 3 -- zestawy cech, 70 -- modeli na otrzymanie uśrednionego R-kwadrat.    

\vspace{5mm}

Algorytm regresji liniowej nie został poddany testom omówionym w obecnym rozdziale. Jako referencyjny i jeden prostszych z algorytmów, nie wymaga ona podania dodatkowych parametrów, aby zadziałał w prawidłowy sposób. W tym przypadku wektor danych wejściowych podczas trenowania przedstawia się  następująco \ref{eqn:regresja}, gdzie $y_i$ jest subiektywną oceną dla filmu $i$, a $x_{1i}, x_{2i}...$ są jego cechami. 

\vspace{7mm}

\subsection{Parametry}


Na podstawie rozdziału 3.4.1 zostały wybrane optymalne parametry. Podczas selekcji brano pod uwagę zarówno wynik dopasowania modelu oraz jego wydajność. Parametry zostały zbiorczo przedstawione w poniższym zestawieniu. Na ich podstawie przygotowano modele dla każdego z zestawów wymienionych w tabeli 3.2.


\begin{itemize}[label=$\bullet$]
	\item SVR --  parametr $C$: 10, parametr $\epsilon$: 0.1, funkcja kernela:  $Radial$ $Basis$ $Function$ (RBF), $\gamma$: auto, 
	
	\item Las losowy -- liczba drzew w modelu: 60, głębokość drzewa 8. 

	\item Sieć neuronowa -- liczba neuronów w pojedynczej warstwie ukrytej: 13, liczba ukrytych warstw: 3, liczba iteracji algorytmu $Backward$ $Propagation$: 1000, $learning$ $rate$: 0,001, funkcja aktywacji: ReLU.\par 
	
\end{itemize}

%Kolejnym testowanym algorytmem był SVR. Użyta funkcja kernela do wyznaczenia hiperpłaszczyzny to $Radial$ $Basis$ $Function$ (RBF). Współczynnikowi $\epsilon$ została przypisana wartość $0,1$. Przy współczynniku $\gamma$, który mówi jak odległe punkty będą miały wpływ na budowaną hiperpłaszczyznę, skorzystano z metody już zaimplementowanej w pakiecie sklearn, pozwalającej na wyznaczenie bardziej dopasowanej wartości, bazując na dostępnym zbiorze danych. Parametr $C$, który odpowiada za wygładzenie funkcji SVR wynosi 0.7.\par
%https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2839056/

%Las losowy działa w oparciu o parametry podane przez badacza, takie jakie jak ilość drzew i ich głębokość. W tym przypadku użyto 100 drzew o głębokości 8.  \par

%Ostatnim sprawdzonym algorytmem uczenia maszynowego była sieć neuronowa z następującymi parametrami -- 3 warstw ukrytych po 13 neuronów w każdej.





\chapter{Wyniki i ich analiza }


Poniższy rozdział prezentuje wyniki z przeprowadzonych badań. Przedstawione zostaną zaobserwowane zależności pomiędzy zestawami danych biorących udział w trenowaniu modeli, a wykorzystanymi algorytmami uczenia maszynowego. W dalszej części tego rozdziału zwrócona zostanie uwaga na pewne dodatkowe spostrzeżenia dotyczące eksploracji danych wynikające z tego opracowania. Na końcu omówiony zostanie model uznany dla niniejszej pracy jako optymalny w ocenie jakości wideo.    
  
    

\begin{figure}[H]
	\includegraphics[ height=10.5cm, width=16cm]{wplyw_alg}
	\captionof{figure}{opis}
	\label{fig:wplyw_alg}
	\label{fig:xccs}
\end{figure}



W pierwszej kolejności wyjaśniane zostaną różnice w obrębie zestawów danych, a pomiędzy poszczególnymi modelami. Sytuacje taką przedstawia wykres \ref{fig:wplyw_alg}, gdzie wyróżnione zostały zestaw 12 i 25.  Różnice takie wynikać mogą z charakterystyki testowanych algorytmów uczenia maszynowego. Niektóre z nich potrafią odnaleźć fałszywe zależności w danych treningowych, które nie wystąpiły w czasie testów, czyli występuje  przeuczenie dla pewnych cech. Inną przyczyną może być rożny poziom dla bias-u dla badanych tu algorytmów, przez którą może nastąpić pominięcie pewnych informacji ukrytych w danych. Każdy z algorytmów przejawia różne właściwości dopasowania do dostępnych danych, co przekłada się na różne poziomy trafności tu prezentowanych modeli. 

Dalej z  powyższego rysunku możemy odczytać, że dla zestawu 25 (wszystkie zebrane cechy, bez metryk FR) sieć neuronowa dała najgorsze wyniki mimo tego, że jest powszechnie uważana za jeden z najbardziej zaawansowanych algorytmów uczenia maszynowego. Wpływ na to mają zapewne dane. Sieci neuronowa daje najlepsze efekty przy bardzo dużych bazach danych, dla puli dostępnej w tym badaniu nie daje ona satysfakcjonujących wyników.  

Dodatkowo obserwując wymienione tu dwa zestawy można zauważyć, że dla zestawu 12 modele w oparciu o sieci neuronowe wypadają lepiej na tle pozostałych algorytmów, niż takie modele dla zestawu 25. Możliwą tego przyczyną  jest brak relacji pomiędzy większą liczbą cech oraz danymi nadzorującymi. W takim przypadku cechy, które maja faktyczny na nie wpływ (w tym badaniu na subiektywną ocenę jakości wideo) mogą zostać nimi zakłócone. Dla lasu losowego to zagorzenie jest mniejsze, ponieważ najistotniejsze pierwsze podziały w drzewie będą opierać się na tych cechach, które mają wpływa na dane nadzorcze. Natomiast węzły decyzyjne oparte na cechach, które mają niewielki wpływ nie będą miały, aż tak dużego znaczenia. \par



Analizując wykres \ref{fig:metryki_fr_nr} można zaobserwować że metryki $full$-$reference$ (zestawy: 1 -- 6, 20, 21) znacznie trafniej dokonują predykcji niż metryki  $no$-$reference$ (zestawy: 22 -- 30). Prawdopodobną przyczyną występowania tej sytuacji są sprzeczne informacje, które dochodzą do algorytmu podczas  trenowania modelu. Przykładowo rozważając blokowość, algorytm może otrzymać wektory danych na temat plików wideo gdzie  ta cecha nie występuje, a jednak badane obrazy otrzymują niską ocenę SVQ, która wynika z innych rodzajów zniekształceń. Wysoki wyniki metryk FR dodatkowo potwierdza powszechną opinię o lepszej skuteczności tych wskaźników jakości.

\begin{figure}[H]
	\includegraphics[ height=12cm, width=16cm]{metryki_fr_nr}
	\captionof{figure}{opis}
	\label{fig:metryki_fr_nr}
	\label{fig:xccs}
\end{figure}

Obserwacja wyników wykazała również, że wprowadzona dodatkowa cecha (liczba dostępnych rozdzielczości)  ma  wpływ na ocenę jakość, choć w niewielkim stopniu. W większości przypadków zestaw z tą cecha otrzymywał wyższe R-kwadrat, niż ten sam zestaw ale bez liczby dostępnych zależności. Wykres kołowy \ref{tab:tabela rozdzielczosc} przedstawia w jakiej części przypadków dana obserwacja się powtarza.\todo{ Podobne sprawdzone tu oddziaływanie to czas trwania. Dla dłuższych wideo  modele daje lepsze wyniki, różnice również są nieznaczne.} \par

\begin{center}
\includegraphics[ height=8cm, width=10cm]{w_kolowy}
\captionof{figure}{Wykres przedstawia stosunek liczby modeli zbudowanych z zestawów z dodatkową cechą, ocenionych jako bardziej trafnych, do liczby przypadków kiedy taki model został oceniony jako gorszy. W 40 przypadkach oceniony, jako lepszy 8 jako gorszy. Rozwarzane zestawy to pary: 14 i 15, 17 i 18, 7 i 8, 11 i 16, 9 i 10, 24 i 25.}
\label{tab:tabela rozdzielczosc}
\label{fig:xccs}
\end{center}
 
%zestawy: 14 i 15, 17 i 18, 7 i 8, 11 i 16, 9 i 10, 24 i 25 są dla siebie bliźniacze z różnicą dodatkowej cechy. Zestawy oznaczone * zawierają dodatkową ceche. Zielony kolor wskazuję na pole z większym R-kwadrat na pare, czerwony na mniejszy(test powtórzony dwa razy). 
%\topskip0pt
%\vspace*{\fill}  
Na wykresie \ref{fig:metryki_fr} można dostrzec, że różnice pomiędzy modelami zbudowanymi na podstawie zestawów: 18, 19, 17, 8, 7, 10, 13, 15, 9, 16, 12, 14, 11, 6  wyróżniają się pod kątem wysokich wartości R-kwadrat. Dla tych zestawów wspólnym mianownikiem są cechy: PSNR, VMAF, SSIM, MS-SSIM. Każda cecha z osobna również osiąga wysokie wyniki (Przykładowo, R-kwadrat kolejno dla modelu Lasu Losowego: 0.490, 0.502,  0.475,  0.507). Niższe jednak niż te osiągnięte w zestawie. 
Wymienione wyżej cechy posiadają wysoki współczynnik korelacji \ref{fig:korelacja}, przez co łączenie ich tylko w pewnym stopniu poprawia trafność modelu. Końcowa wartość nie jest ich sumą. Przykładowo dla zestawu 2 (VMAF + SSIM) R-kwadrat wynosi 0.636 \par
\vspace*{\fill}

\begin{figure}
	\includegraphics[ height=10cm, width=16cm]{metryki_fr}
	\captionof{figure}{opis}
	\label{fig:metryki_fr}
	\label{fig:xccs}
\end{figure}

\begin{center}
\includegraphics[ height=14cm, width=14cm]{korelacja}
\captionof{figure}{Korelacja pomiędzy poszczególnymi cechami.}
\label{fig:korelacja}
\label{fig:xccs}
\end{center}



\topskip0pt
\vspace*{\fill} 
Inne jeszcze zjawisko, które można odnotować czytając wykres \ref{fig:negatywny_r}, to ujemna wartość R-kwadrat dla niektórych zestawów. Biorąc pod uwagę wzór \ref{eqn:r2}, zauważyć należy to, że model podczas testów dokonywał gorszej predykcji, niż średnia dla zbioru danych testowych. Tą sytuację przedstawia wykres \ref{fig:kontrast_ujemne_rk}. Zaprezentowane są tu próbki danych dla cechy kontrast. Funkcja regresji liniowej (linia niebieska)  pokrywa się ze średnią dla danych testowych (linia pomarańczowa), ale podczas liczenia R-kwadrat brana pod uwagę jest średnia ze zbioru danych testowych (linia czerwona). Gdyby ta ostania pokrywała się z linią regresji R-kwadrat wynosił by 0. Ujemny, R-kwadrat oznacza również, że dla danej cechy lub ich zestawu, algorytm nie odnalazł zależności między zmiennymi opisującymi, a zmienną opisywaną.\par
\vspace*{\fill}

\begin{center}
	\includegraphics[ height=10cm, width=13cm]{negatywny_r}
	\captionof{figure}{ops.}
	\label{fig:negatywny_r}
	\label{fig:xccs}
\end{center}

\begin{center}
\includegraphics[ height=10cm, width=13cm]{kontrast_ujemne_rk}
\captionof{figure}{Przypadek kiedy wskaźnik r-kwadrat jest ujemny.}
\label{fig:kontrast_ujemne_rk}
\label{fig:xccs}
\end{center}

Najwyższy uśredniony wynik R-kwadrat został osiągnięty przez modele zbudowane na podstawie algorytmu \textbf{lasu losowego} (z zadanymi wcześniej parametrami) z użyciem \textbf{zestawu 18}, czyli \textbf{0.824}. Należy stwierdzić, że dla większości tu przeprowadzonych badań, algorytm lasu losowego osiągał najlepsze wyniki.  Może to być związane ze większą jego odpornością na wariację  w szczególności dla dobrze dobranych parametrów. Wyróżniony tutaj zestaw 18 składa się z  zebranych metryk full-reference z uwzględnieniem czasu trwania wideo i dodatkowej cechy dotyczącej ilości dostępnych rozdzielczości. Każdy z modeli z tej grupy daje nieco inne  wyniki (odchylenie standardowe wynosi 0.053, jest stosunkowo nieduże w porównaniu z innymi modelami i zestawami) ponieważ budowany jest na różnych próbkach danych.  Odnosząc się do tematu pracy, ma on największe szanse na trafne wyznaczenie jakość wideo. Podobnie jak [link do badan robionych w podobny sposób]\todo{text}i w tym przypadku jako szukany model należy uznać jeden ze stu modeli dla tych/tu wyróżnionych parametrów. 

%\begin{sidewaysfigure}[ht]
%	\includegraphics[ height=15cm, width=26cm]{podsumowanie}
%	\captionof{figure}{Wyniki z poszczególnych modeli}
%	\label{fig:podsumowanie}
%	\label{fig:xccs}
%\end{sidewaysfigure}


\chapter{Podsumowanie}

\todo{ewentualnie -  dodac sprawdzenei mojej metryki z wskaznikiem koralacji Pearson'a, jezeli > 0.9 to dobra metryka }


Prezentowana praca stawiała sobie za cel stworzenie algorytmu oceniającego jakość wideo.

Po uprzednim przygotowaniu danych, do dyspozycji badającego były informacje opisujące wideo –- zarówno metryki FR jak i NR. Metryki zostały wykorzystane do zbudowania i przystosowania czterech pul modeli w oparciu o  cztery algorytmy uczenia maszynowego. Wykreowane modele mogą posłużyć jako algorytmy oceniające jakość wideo.

Zmierzając do zniwelowania różnic wynikających ze specyficznego podziału danych stworzono ponad 70 modeli dla każdego z algorytmów, gdzie, na podstawie uśrednionego wyniku R-kwadrat, został wybrany optymalny algorytm (wraz z parametrami) i zestaw cech - jako dane wejściowe. Odnosząc się do tematu pracy, algorytmem oceniającym jakość jest jeden z modeli przygotowany w oparciu o wyżej wymienione czynniki -- Las Losowy składający się z 60 drzew o głębokości 8 wraz cechami z zestawu 18 [link do zserializowanego modelu].\todo{text}

Co więcej, można postawić tezę, że chociaż wszystkie metryki FR, w tym badaniu, mają wysokie wartości R-kwadrat, to jednak możliwa jest sytuacja, kiedy ich ocena znacząco będzie odbiegać od SQV. Wideo referencyjne może już na samym początku może być zniekształcone poprzez nieprawidłowe nagranie. Policzony wtedy PSNR dla SRC i PVS wykaże wysoką jakość obrazu ale ocena odbiorcy będzie negatywna.

Przedstawione w obecnym studium rozwiązanie nie jest uniwersalnym wyznacznikiem jakości wideo. Z pewnością mogą istnieć czynniki, które nie zostały w pracy uwzględnione. Z faktu, że badanie korzysta z oceny ludzkiej jako cechy nadzorującej mogą wynikać nie brane pod uwagę efekty zmieniające tę ocenę.

Należy stwierdzić, że z biegiem lat oczekiwania co do jakości wideo znacznie rosną. Chociaż w latach 90 ubiegłego wieku tamtejsze wideo uznawane było jako produkt wysokiej klasy, to współcześni widzowie nie byliby w żaden sposób usatysfakcjonowani odbiorem takiego obrazu. 

Dodatkowo, biorąc dynamicznie rozwijający się rynek multimediów, warto zwrócić uwagę na nowe technologie jeszcze nie tak mocno spopularyzowane. Dla nich może się okazać, że żadna z do tej pory dostępnych metryk, również ta  zaproponowana w niniejszej pracy,  nie spełnia oczekiwań. Przykładowo niebrany do tej pory pod uwagę w czasie badań rodzaj wideo wykorzystywana w VR (\textit{ang. Virtual Reality}) -- wideo 360.  

Przeprowadzone badania i zebrane dane mogą posłużyć do dalszych bardziej
zaawansowanych studiów nad jakością wideo. Przykładowo mogły by one uwzględniać aktualny rodzaj zniekształceń i warunków odbioru dla widza i na tej podstawie stworzyć metrykę, która dostosowuje się do tak zadanej sytuacji.


\label{cha:pierwszyDokument}









